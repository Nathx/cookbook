{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import csv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_reviews(path, **kwargs):\n",
    "    \"\"\"Load MovieLens reviews.\"\"\"\n",
    "    \n",
    "    options = {\n",
    "        'fieldnames': ('userid', 'movieid', 'rating', \n",
    "                       'timestamp'),\n",
    "        'delimiter': '\\t'\n",
    "    }\n",
    "    options.update(kwargs)\n",
    "    \n",
    "    parse_date = lambda r,k: datetime.date.fromtimestamp(float(r[k]))\n",
    "    parse_int = lambda r,k: int(r[k])\n",
    "    \n",
    "    with open(path, 'rb') as reviews:\n",
    "        reader = csv.DictReader(reviews, **options)\n",
    "        for row in reader:\n",
    "            row['userid'] = parse_int(row, 'userid')\n",
    "            row['movieid'] = parse_int(row, 'movieid')\n",
    "            row['rating'] = parse_int(row, 'rating')\n",
    "            row['timestamp'] = parse_date(row, 'timestamp')\n",
    "            yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Recommender(object):\n",
    "    \n",
    "    @classmethod\n",
    "    def load(klass, pickle_path):\n",
    "        \"\"\"\n",
    "        Instantiates the class by deserializing the pickle. Note that the\n",
    "        object returned may not be an exact match to the code in this\n",
    "        class (if it was saved before updates).\n",
    "        \"\"\"\n",
    "        with open(pickle_path, 'rb') as pkl:\n",
    "            return pickle.load(pkl)\n",
    "    \n",
    "    def __init__(self, udata):\n",
    "        self.udata = udata\n",
    "        self.users = None\n",
    "        self.movies = None\n",
    "        self.reviews = None\n",
    "        \n",
    "        # Descriptive properties\n",
    "        self.build_start = None\n",
    "        self.build_finish = None\n",
    "        self.description = None\n",
    "        \n",
    "        # Model properties\n",
    "        self.model = None\n",
    "        self.features = 2\n",
    "        self.steps = 5000\n",
    "        self.alpha = 0.0002\n",
    "        self.beta = 0.02\n",
    "        \n",
    "        self.load_dataset()\n",
    "        \n",
    "    def dump(self, pickle_path):\n",
    "        \"\"\"\n",
    "        Dump the object into a serialized file using the pickle module.\n",
    "        This will allow us to quickly reload our model in the future.\n",
    "        \"\"\"\n",
    "        with open(pickle_path, 'wb') as pkl:\n",
    "            pickle.dump(self, pkl)\n",
    "        \n",
    "    def load_dataset(self):\n",
    "        \"\"\"\n",
    "        Loads an index of users and movies as a heap and a reviews table\n",
    "        as a N x M array where N is the number of users and M is the number\n",
    "        of movies. Note that order matters so that we can look up values\n",
    "        outside of the matrix!\n",
    "        \"\"\"\n",
    "        self.users = set([])\n",
    "        self.movies = set([])\n",
    "        for review in load_reviews(self.udata):\n",
    "            self.users.add(review['userid'])\n",
    "            self.movies.add(review['movieid'])\n",
    "            \n",
    "        self.users = sorted(self.users)\n",
    "        self.movies = sorted(self.movies)\n",
    "        \n",
    "        self.reviews = np.zeros(shape=(len(self.users), len(self.movies)))\n",
    "        for review in load_reviews(self.udata):\n",
    "            uid = self.users.index(review['userid'])\n",
    "            mid = self.movies.index(review['movieid'])\n",
    "            self.reviews[uid, mid] = review['rating']\n",
    "            \n",
    "\n",
    "    def build(self, output=None):\n",
    "        \"\"\"\n",
    "        Trains the model by employing matrix factorization on our training\n",
    "        data set, the sparse reviews matrix. The model is the dot product\n",
    "        of the P and Q decomposed matrices from the factorization.\n",
    "        \"\"\"\n",
    "        options = {\n",
    "            'K': self.features,\n",
    "            'steps': self.steps,\n",
    "            'alpha': self.alpha,\n",
    "            'beta': self.beta\n",
    "        }\n",
    "        \n",
    "        self.build_start = time.time()\n",
    "        self.P, self.Q = factor(self.reviews, **options)\n",
    "        self.model = np.dot(self.P, self.Q.T)\n",
    "        self.build_finish = time.time()\n",
    "        \n",
    "        if output:\n",
    "            self.dump(output)\n",
    "            \n",
    "\n",
    "    def sparsity(self):\n",
    "        \"\"\"Returns the percent of elements that are zero in the array.\"\"\"\n",
    "        return 1 - self.density()\n",
    "    \n",
    "    def density(self):\n",
    "        \"\"\"Returns the percent of elements that are nonzero in the array.\"\"\"\n",
    "        nonzero = float(np.count_nonzero(self.reviews))\n",
    "        return nonzero / self.reviews.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = 'data/ml-100k/u.data'\n",
    "model = Recommender(data_path)\n",
    "model.reviews = model.reviews[:100,:100]\n",
    "model.build('record.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize(R, K):\n",
    "    \"\"\"Returns initial matrices for an N x M matrix,\n",
    "    R and K features.\n",
    "\n",
    "    :returns: P, Q initial matrices of N x K and M x K sizes.\n",
    "    \"\"\"\n",
    "\n",
    "    N, M = R.shape\n",
    "    P = np.random.rand(N, K)\n",
    "    Q = np.random.rand(M, K)\n",
    "    return P, Q\n",
    "\n",
    "def factor(R, P=None, Q=None, K=2, steps=5000, alpha=0.0002, \n",
    "           beta=0.02):\n",
    "    \"\"\"\n",
    "    Performs matrix factorization on R with given parameters.\n",
    "\n",
    "    :param R: A matrix to be factorized, dimension N x M\n",
    "    :param P: an initial matrix of dimension N x K\n",
    "    :param Q: an initial matrix of dimension M x K\n",
    "    :param K: the number of latent features\n",
    "    :param steps: the maximum number of iterations to optimize in\n",
    "    :param alpha: the learning rate for gradient descent\n",
    "    :param beta:  the regularization parameter\n",
    "\n",
    "    :returns: final matrices P and Q\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(P, np.ndarray) or not isinstance(Q, np.ndarray):\n",
    "        P, Q = initialize(R, K)\n",
    "    Q = Q.T\n",
    "\n",
    "    rows, cols = R.shape\n",
    "    for step in xrange(steps):\n",
    "        for i in xrange(rows):\n",
    "            for j in xrange(cols):\n",
    "                if R[i,j] > 0:\n",
    "                    eij = R[i,j] - np.dot(P[i,:], Q[:,j])\n",
    "                    for k in xrange(K):\n",
    "                        P[i,k] = P[i,k] + alpha * (2 * eij * Q[k,j] -\n",
    "                                                  beta * P[i,k])\n",
    "                        Q[k,j] = Q[k,j] + alpha * (2 * eij * P[i,k] -\n",
    "                                                  beta * Q[k,j])\n",
    "        e = 0\n",
    "        for i in xrange(rows):\n",
    "            for j in xrange(cols):\n",
    "                if R[i,j] > 0:\n",
    "                    e = e + pow(R[i,j] - np.dot(P[i,:], Q[:,j]), 2)\n",
    "                    for k in xrange(K):\n",
    "                        e = e + (beta/2) * (pow(P[i,k], 2) + pow(Q[k,j], 2))\n",
    "\n",
    "        if e < 0.001:\n",
    "            break\n",
    "\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386.531332016\n"
     ]
    }
   ],
   "source": [
    "delta = model.build_finish - model.build_start\n",
    "print delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(P, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
