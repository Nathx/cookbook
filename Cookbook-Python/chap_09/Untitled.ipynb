{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_reviews(path, **kwargs):\n",
    "    \"\"\"Load MovieLens reviews.\"\"\"\n",
    "    \n",
    "    options = {\n",
    "        'fieldnames': ('userid', 'movieid', 'rating', \n",
    "                       'timestamp'),\n",
    "        'delimiter': '\\t'\n",
    "    }\n",
    "    options.update(kwargs)\n",
    "    \n",
    "    parse_date = lambda r,k: datetime.date.fromtimestamp(float(r[k]))\n",
    "    parse_int = lambda r,k: int(r[k])\n",
    "    \n",
    "    with open(path, 'rb') as reviews:\n",
    "        reader = csv.DictReader(reviews, **options)\n",
    "        for row in reader:\n",
    "            row['userid'] = parse_int(row, 'userid')\n",
    "            row['movieid'] = parse_int(row, 'movieid')\n",
    "            row['rating'] = parse_int(row, 'rating')\n",
    "            row['timestamp'] = parse_date(row, 'timestamp')\n",
    "            yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relative_path(path):\n",
    "    \"\"\"Returns a path relative from this code file.\"\"\"\n",
    "    \n",
    "    dirname = os.path.dirname(os.path.realpath('__file__'))\n",
    "    path = os.path.join(dirname, path)\n",
    "    return os.path.normpath(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_movies(path, **kwargs):\n",
    "    \"\"\"\n",
    "    Loads Movielens movies\n",
    "    \"\"\"\n",
    "\n",
    "    options = {\n",
    "        'fieldnames': ('movieid', 'title', 'release', 'video', 'url'),\n",
    "        'delimiter': '|',\n",
    "        'restkey': 'genre',\n",
    "    }\n",
    "    options.update(kwargs)\n",
    "\n",
    "    parse_int  = lambda r,k: int(r[k])\n",
    "    parse_date = lambda r,k: datetime.datetime.strptime(r[k], '%d-%b-%Y') if r[k] else None\n",
    "\n",
    "    with open(path, 'rb') as movies:\n",
    "        reader = csv.DictReader(movies, **options)\n",
    "        for row in reader:\n",
    "            row['movieid'] = parse_int(row, 'movieid')\n",
    "            row['release'] = parse_date(row, 'release')\n",
    "            row['video']   = parse_date(row, 'video')\n",
    "            yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MovieLens(object):\n",
    "    \"\"\"Data structure to build our recommender model on.\"\"\"\n",
    "    \n",
    "    def __init__(self, udata, uitem):\n",
    "        \"\"\"Instantiate with a path to u.data and u.item.\"\"\"\n",
    "        self.udata = udata\n",
    "        self.uitem = uitem\n",
    "        self.movies = {}\n",
    "        self.reviews = defaultdict(dict)\n",
    "        self.load_dataset()\n",
    "        \n",
    "    def load_dataset(self):\n",
    "        \"\"\"\n",
    "        Loads the 2 datasets into memory, \n",
    "        indexed on the ID.\n",
    "        \"\"\"\n",
    "        for movie in load_movies(self.uitem):\n",
    "            self.movies[movie['movieid']] = movie\n",
    "            \n",
    "        for review in load_reviews(self.udata):\n",
    "            self.reviews[review['userid']][\n",
    "                review['movieid']] = review\n",
    "            \n",
    "    def reviews_for_movie(self, movieid):\n",
    "        \"\"\"Yields the reviews for a given movie.\"\"\"\n",
    "        for review in self.reviews.values():\n",
    "            if movieid in review:\n",
    "                yield review[movieid]\n",
    "                \n",
    "    def average_reviews(self):\n",
    "        \"\"\"\n",
    "        Averages the star ratings for all movies.\n",
    "        Yields a tuple of movieid,\n",
    "        the average rating, and the number of reviews.\n",
    "        \"\"\"\n",
    "        for movieid in self.movies:\n",
    "            reviews = list(r['rating'] for r in self.reviews_for_movie(movieid))\n",
    "            average = sum(reviews) / float(len(reviews))\n",
    "            yield (movieid, average, len(reviews))\n",
    "            \n",
    "    def top_rated(self, n=10):\n",
    "        \"\"\"Yields the n top rated movies.\"\"\"\n",
    "        return heapq.nlargest(n, self.bayesian_average(), key = itemgetter(1))\n",
    "    \n",
    "    def bayesian_average(self, c=59, m=3):\n",
    "        \"\"\"Reports the Bayesian average with parameters c and m.\"\"\"\n",
    "        for movieid in self.movies:\n",
    "            reviews = list(r['rating'] for r in self.reviews_for_movie(movieid))\n",
    "            average = ((c * m) + sum(reviews)) / float(c + len(reviews))\n",
    "            yield (movieid, average, len(reviews))\n",
    "            \n",
    "    def shared_preferences(self, criticA, criticB):\n",
    "        \"\"\"Returns the intersection of ratings for two critics.\"\"\"\n",
    "        \n",
    "        if criticA not in self.reviews:\n",
    "            raise KeyError(\"Couldn't find critic '%s' in data\" % criticA)\n",
    "        if criticB not in self.reviews:\n",
    "            raise KeyError(\"Couldn't find critic '%s' in data\" % criticB)\n",
    "            \n",
    "        moviesA = set(self.reviews[criticA].keys())\n",
    "        moviesB = set(self.reviews[criticB].keys())\n",
    "        shared = moviesA & moviesB # Intersection operator\n",
    "        \n",
    "        # Create a reviews dictionary to return\n",
    "        reviews = {}\n",
    "        for movieid in shared:\n",
    "            reviews[movieid] = (\n",
    "                self.reviews[criticA][movieid][\"rating\"],\n",
    "                self.reviews[criticB][movieid][\"rating\"]\n",
    "            )\n",
    "        return reviews\n",
    "    \n",
    "    def shared_critics(self, movieA, movieB):\n",
    "        \"\"\"\n",
    "        Returns the intersection of critics for two items, A and B\n",
    "        \"\"\"\n",
    "\n",
    "        if movieA not in self.movies:\n",
    "            raise KeyError(\"Couldn't find movie '%s' in data\" % movieA)\n",
    "        if movieB not in self.movies:\n",
    "            raise KeyError(\"Couldn't find movie '%s' in data\" % movieB)\n",
    "\n",
    "        criticsA = set(critic for critic in self.reviews if movieA in self.reviews[critic])\n",
    "        criticsB = set(critic for critic in self.reviews if movieB in self.reviews[critic])\n",
    "        shared   = criticsA & criticsB # Intersection operator\n",
    "\n",
    "        # Create the reviews dictionary to return\n",
    "        reviews  = {}\n",
    "        for critic in shared:\n",
    "            reviews[critic] = (\n",
    "                self.reviews[critic][movieA]['rating'],\n",
    "                self.reviews[critic][movieB]['rating'],\n",
    "            )\n",
    "        return reviews\n",
    "    \n",
    "    def euclidean_distance(self, criticA, criticB, prefs='users'):\n",
    "        \"\"\"\n",
    "        Reports the Euclidean distance of two critics, A and B by\n",
    "        performing a J-dimensional Euclidean calculation of each of their\n",
    "        preference vectors for the intersection of books the critics have\n",
    "        rated.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the intersection of the rated titles in the data.\n",
    "\n",
    "        if prefs == 'users':\n",
    "            preferences = self.shared_preferences(criticA, criticB)\n",
    "        elif prefs == 'movies':\n",
    "            preferences = self.shared_critics(criticA, criticB)\n",
    "        else:\n",
    "            raise Exception(\"No preferences of type '%s'.\" % prefs)\n",
    "\n",
    "        # If they have no rankings in common, return 0.\n",
    "        if len(preferences) == 0: return 0\n",
    "\n",
    "        # Sum the squares of the differences\n",
    "        sum_of_squares = sum([abs(a-b) for a, b in preferences.values()])\n",
    "\n",
    "        # Return the inverse of the distance to give a higher score to\n",
    "        # folks who are more similar (e.g. less distance) add 1 to prevent\n",
    "        # division by zero errors and normalize ranks in [0, 1]\n",
    "        return 1 / (1 + sqrt(sum_of_squares))\n",
    "    \n",
    "    def pearson_correlation(self, criticA, criticB, prefs='users'):\n",
    "        \"\"\"\n",
    "        Returns the Pearson Correlation of two critics, A and B by\n",
    "        performing the PPMC calculation on the scatter plot of (a, b)\n",
    "        ratings on the shared set of critiqued titles.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the set of mutually rated items\n",
    "        if prefs == 'users':\n",
    "            preferences = self.shared_preferences(criticA, criticB)\n",
    "        elif prefs == 'movies':\n",
    "            preferences = self.shared_critics(criticA, criticB)\n",
    "        else:\n",
    "            raise Exception(\"No preferences of type '%s'.\" % prefs)\n",
    "\n",
    "        # Store the length to save traversals of the len computation.\n",
    "        # If they have no rankings in common, return 0.\n",
    "        length = len(preferences)\n",
    "        if length == 0: return 0\n",
    "\n",
    "        # Loop through the preferences of each critic once and compute the\n",
    "        # various summations that are required for our final calculation.\n",
    "        sumA = sumB = sumSquareA = sumSquareB = sumProducts = 0\n",
    "        for a, b in preferences.values():\n",
    "            sumA += a\n",
    "            sumB += b\n",
    "            sumSquareA  += pow(a, 2)\n",
    "            sumSquareB  += pow(b, 2)\n",
    "            sumProducts += a*b\n",
    "\n",
    "        # Calculate Pearson Score\n",
    "        numerator   = (sumProducts*length) - (sumA*sumB)\n",
    "        denominator = sqrt(((sumSquareA*length) - pow(sumA, 2))\n",
    "                            * ((sumSquareB*length) - pow(sumB, 2)))\n",
    "\n",
    "        # Prevent division by zero.\n",
    "        if denominator == 0: return 0\n",
    "\n",
    "        return abs(numerator / denominator)\n",
    "    \n",
    "    def similar_critics(self, user, metric='euclidian', n=None):\n",
    "        \"\"\"\n",
    "        Finds, ranks similar critics for the user according to the \n",
    "        specified distance metric. Returns the topn similar critics\n",
    "        if n is specified.\n",
    "        \"\"\"\n",
    "\n",
    "        # Metrics jump table\n",
    "        metrics = {\n",
    "            'euclidian': self.euclidean_distance,\n",
    "            'pearson': self.pearson_correlation\n",
    "        }\n",
    "\n",
    "        distance = metrics.get(metric, None)\n",
    "\n",
    "        # Handle problems that might occur\n",
    "        if user not in self.reviews:\n",
    "            raise KeyError(\"Unknown user, '%s'.\" % user)\n",
    "        if not distance or not callable(distance):\n",
    "            raise KeyError(\"Unknown or unprogrammed distance metric '%s'.\" % metric)\n",
    "\n",
    "        # Compute user to critic similarities for all critics\n",
    "        critics = {}\n",
    "        for critic in self.reviews:\n",
    "            # Don't compare against yourself.\n",
    "            if critic == user:\n",
    "                continue\n",
    "            critics[critic] = distance(user, critic)\n",
    "            \n",
    "        if n:\n",
    "            return heapq.nlargest(n, critics.items(),\n",
    "                                 key = itemgetter(1))\n",
    "        return critics\n",
    "    \n",
    "    def similar_items(self, movie, metric='euclidean', n=None):\n",
    "        # Metric jump table\n",
    "        metrics  = {\n",
    "            'euclidean': self.euclidean_distance,\n",
    "            'pearson':   self.pearson_correlation,\n",
    "        }\n",
    "\n",
    "        distance = metrics.get(metric, None)\n",
    "\n",
    "        # Handle problems that might occur\n",
    "        if movie not in self.reviews:\n",
    "            raise KeyError(\"Unknown movie, '%s'.\" % movie)\n",
    "        if not distance or not callable(distance):\n",
    "            raise KeyError(\"Unknown or unprogrammed distance metric '%s'.\" % metric)\n",
    "\n",
    "        items = {}\n",
    "        for item in self.movies:\n",
    "            if item == movie:\n",
    "                continue\n",
    "\n",
    "            items[item] = distance(item, movie, prefs='movies')\n",
    "\n",
    "        if n:\n",
    "            return heapq.nlargest(n, items.items(), key=itemgetter(1))\n",
    "        return items\n",
    "    \n",
    "    def predict_ranking(self, user, movie, metric='euclidean', critics=None, C=59, m=3):\n",
    "        \"\"\"\n",
    "        Predicts the ranking a user might give a movie according to the\n",
    "        weighted average of the critics that are similar to the that user.\n",
    "        \"\"\"\n",
    "\n",
    "        critics = critics or self.similar_critics(user, metric=metric)\n",
    "        total   = 0.0\n",
    "        simsum  = 0.0\n",
    "\n",
    "        for critic, similarity in critics.items():\n",
    "            if movie in self.reviews[critic]:\n",
    "                total  += similarity * self.reviews[critic][movie]['rating']\n",
    "                simsum += similarity\n",
    "\n",
    "        if simsum == 0.0: return 0.0\n",
    "        return (C*m + total) / (C + simsum)\n",
    "    \n",
    "\n",
    "    def predict_all_rankings(self, user, metric='euclidean', n=None):\n",
    "        \"\"\"\n",
    "        Predicts all rankings for all movies, if n is specified returns\n",
    "        the top n movies and their predicted ranking.\n",
    "        \"\"\"\n",
    "        critics = self.similar_critics(user, metric=metric)\n",
    "        movies = {\n",
    "            movie: self.predict_ranking(user, movie, metric, critics)\n",
    "            for movie in self.movies\n",
    "        }\n",
    "\n",
    "        if n:\n",
    "            return heapq.nlargest(n, movies.items(), key=itemgetter(1))\n",
    "        return movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.89174298531\n"
     ]
    }
   ],
   "source": [
    "data = relative_path('data/ml-100k/u.data')\n",
    "item = relative_path('data/ml-100k/u.item')\n",
    "model = MovieLens(data, item)\n",
    "print model.predict_ranking(422, 50, 'euclidian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9809962268\n"
     ]
    }
   ],
   "source": [
    "print model.predict_ranking(422, 50, 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{258: {'movieid': 258, 'userid': 578, 'timestamp': datetime.date(1998, 3, 3), 'rating': 1}, 268: {'movieid': 268, 'userid': 578, 'timestamp': datetime.date(1998, 3, 26), 'rating': 2}, 272: {'movieid': 272, 'userid': 578, 'timestamp': datetime.date(1998, 3, 3), 'rating': 2}, 288: {'movieid': 288, 'userid': 578, 'timestamp': datetime.date(1998, 2, 11), 'rating': 3}, 678: {'movieid': 678, 'userid': 578, 'timestamp': datetime.date(1998, 3, 3), 'rating': 3}, 298: {'movieid': 298, 'userid': 578, 'timestamp': datetime.date(1998, 3, 3), 'rating': 4}, 300: {'movieid': 300, 'userid': 578, 'timestamp': datetime.date(1998, 2, 11), 'rating': 4}, 313: {'movieid': 313, 'userid': 578, 'timestamp': datetime.date(1998, 2, 11), 'rating': 5}, 323: {'movieid': 323, 'userid': 578, 'timestamp': datetime.date(1998, 3, 3), 'rating': 3}, 324: {'movieid': 324, 'userid': 578, 'timestamp': datetime.date(1998, 3, 3), 'rating': 1}, 325: {'movieid': 325, 'userid': 578, 'timestamp': datetime.date(1998, 3, 3), 'rating': 1}, 1098: {'movieid': 1098, 'userid': 578, 'timestamp': datetime.date(1998, 3, 26), 'rating': 2}, 343: {'movieid': 343, 'userid': 578, 'timestamp': datetime.date(1998, 3, 3), 'rating': 2}, 346: {'movieid': 346, 'userid': 578, 'timestamp': datetime.date(1998, 2, 11), 'rating': 3}, 222: {'movieid': 222, 'userid': 578, 'timestamp': datetime.date(1998, 3, 3), 'rating': 4}, 355: {'movieid': 355, 'userid': 578, 'timestamp': datetime.date(1998, 3, 3), 'rating': 1}, 294: {'movieid': 294, 'userid': 578, 'timestamp': datetime.date(1998, 3, 3), 'rating': 3}, 751: {'movieid': 751, 'userid': 578, 'timestamp': datetime.date(1998, 2, 11), 'rating': 3}, 1264: {'movieid': 1264, 'userid': 578, 'timestamp': datetime.date(1998, 3, 26), 'rating': 3}, 245: {'movieid': 245, 'userid': 578, 'timestamp': datetime.date(1998, 2, 11), 'rating': 3}, 246: {'movieid': 246, 'userid': 578, 'timestamp': datetime.date(1998, 3, 26), 'rating': 2}, 1016: {'movieid': 1016, 'userid': 578, 'timestamp': datetime.date(1998, 3, 3), 'rating': 4}, 250: {'movieid': 250, 'userid': 578, 'timestamp': datetime.date(1998, 3, 3), 'rating': 2}, 380: {'movieid': 380, 'userid': 578, 'timestamp': datetime.date(1998, 3, 3), 'rating': 3}}\n"
     ]
    }
   ],
   "source": [
    "print model.reviews[578]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Wars (1977): 4.026\n",
      "Godfather, The (1972): 3.874\n",
      "Schindler's List (1993): 3.871\n",
      "Shawshank Redemption, The (1994): 3.863\n",
      "Fargo (1996): 3.843\n",
      "Raiders of the Lost Ark (1981): 3.826\n",
      "Silence of the Lambs, The (1991): 3.824\n",
      "Casablanca (1942): 3.808\n",
      "Titanic (1997): 3.805\n",
      "Usual Suspects, The (1995): 3.802\n"
     ]
    }
   ],
   "source": [
    "for mid, rating in model.predict_all_rankings(578, 'pearson', 10):\n",
    "    print \"%s: %0.3f\" % (model.movies[mid]['title'], rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
